
@page
@model IndexModel
@{
    ViewData["Title"] = "Home page";
}

<head>
    <script src="js/face-api.js"></script>
    <script src="js/commons.js"></script>
    <script src="js/drawing.js"></script>
    <script src="js/faceDetectionControls.js"></script>
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>

<body>
    @*<div class="center-content page-container">
        <div style="position: center" class="margin">
            <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
            <canvas id="overlay" />
        </div>
    </div>*@

    <div class="center-content page-container">
        <div class="progress" id="loader">
            <div class="indeterminate"></div>
        </div>
        <div style="position: relative" class="margin">
            <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
            <canvas id="overlay" />
        </div>
    </div>


    <script>
        let forwardTimes = []
        let withFaceLandmarks = false
        let withBoxes = true

        function onChangeWithFaceLandmarks(e) {
            withFaceLandmarks = $(e.target).prop('checked')
        }

        function onChangeHideBoundingBoxes(e) {
            withBoxes = !$(e.target).prop('checked')
        }

        function updateTimeStats(timeInMs) {
            forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
            const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
            //$('#time').val(`${Math.round(avgTimeInMs)} ms`)
            //$('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
        }

        async function onPlay() {
            const videoEl = $('#inputVideo').get(0)

            if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
                return setTimeout(() => onPlay())


            const options = getFaceDetectorOptions()

            const ts = Date.now()

            const faceDetectionTask = faceapi.detectSingleFace(videoEl, options)
            const result = withFaceLandmarks
                ? await faceDetectionTask.withFaceLandmarks()
                : await faceDetectionTask

            updateTimeStats(Date.now() - ts)

            const drawFunction = withFaceLandmarks
                ? drawLandmarks
                : drawDetections

            if (result) {
                drawFunction(videoEl, $('#overlay').get(0), [result], withBoxes)
            }

            setTimeout(() => onPlay())
        }

        async function run() {
            // load face detection and face landmark models
            //await changeFaceDetector(SSD_MOBILENETV1)
            await changeFaceDetector(TINY_FACE_DETECTOR)
            await faceapi.loadFaceLandmarkModel('/')
            changeInputSize(128)

            // try to access users webcam and stream the images
            // to the video element
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
            const videoEl = $('#inputVideo').get(0)
            videoEl.srcObject = stream
        }

        function updateResults() { }

        $(document).ready(function () {
            //renderNavBar('#navbar', 'webcam_face_tracking')
            //initFaceDetectionControls()
            run()
        })
    </script>
</body>